# **第3节 基于 InternLM 和 LangChain 搭建你的知识库**
#### Jan 15 2024 
#### [文档](https://github.com/InternLM/tutorial/tree/main/langchain)  
## 1. LLM的局限性
#### 1.1 知识时效性受限
#### 1.2 专业能力有限 如何打造垂域大模理
#### 1.3 定制化成本高 如何打造人人专属的LLM应用
## 2. RAG vs Finetune
### 2.1 RAG 检索增强生成
## 3.构建向量数据库
#### 3.1 加载源文件   文档分块   文档向量化
## 4. 搭建知识库助手
### 4.1 将InterLM接入langchain
#### 4.2 构建检索问答链
#####    4.2.1 检索方面基于语义进行分割，何证每一个chunk的语义完整
## 5.Web Demo 部署
#### 5.1 支持简易Web部署框架：Gradio, Streamlit
